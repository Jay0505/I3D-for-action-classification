{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv3D, ReLU, BatchNormalization, MaxPool3D, AveragePooling3D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "config = edict()\n",
    "\n",
    "config.BATCH_SIZE = 1\n",
    "config.NUM_CLASSES = 5\n",
    "config.NUM_EPOCHS = 2\n",
    "config.NUM_BATCHES_PER_EPOCH = 3\n",
    "config.NUM_FRAMES = 105\n",
    "config.RGB_ARRAY_DIR = '/Users/vijay/Downloads/Code_Data/I3D_scratch/rgb_data/'\n",
    "config.FLOW_ARRAY_DIR = '/Users/vijay/Downloads/Code_Data/I3D_scratch/flow_data/'\n",
    "config.RGB_CHECKPOINT_DIR   = '/Users/vijay/Downloads/Code_Data/I3D_scratch/checkpoints/rgb/'\n",
    "config.FLOW_CHECKPOINT_DIR   = '/Users/vijay/Downloads/Code_Data/I3D_scratch/checkpoints/flow/'\n",
    "config.FINAL_WEIGHTS_DIR = '/Users/vijay/Downloads/Code_Data/I3D_scratch/checkpoints/final/'\n",
    "config.CHECKPOINT_DIR   = '/Users/vijay/Downloads/Code_Data/I3D_scratch/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#############################################################\n",
    "############## RGB AND NPY ARRAYS ###########################\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "def get_scaled_video(video_path):\n",
    "    '''\n",
    "    As per the paper, first we have to resize the smaller video side to 256 pixels\n",
    "    '''\n",
    "    scaled_video = []\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_width = video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    frame_height = video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    \n",
    "    if min(frame_width, frame_height) != 256:\n",
    "        scale = 256.0 / min(frame_width, frame_height)\n",
    "    \n",
    "    scaled_width = int(frame_width * scale)\n",
    "    scaled_height = int(frame_height * scale)\n",
    "    \n",
    "    while(video_capture.isOpened()):\n",
    "\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (scaled_width, scaled_height))\n",
    "            scaled_video.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return np.asarray(scaled_video), frame_count, fps, scaled_width, scaled_height\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_video_with_frames_every_second(video_array, fps, num_of_frames, duration_of_video):\n",
    "    return_video_array = []\n",
    "    diff = duration_of_video - num_of_frames\n",
    "    start_frame_num = diff * fps\n",
    "    for frame_num, frame in enumerate(video_array):\n",
    "        if frame_num >= start_frame_num:\n",
    "            if frame_num % fps == 0:\n",
    "                return_video_array.append(frame)\n",
    "    \n",
    "    return np.asarray(return_video_array)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_req_num_of_frames_from_scaled_video(scaled_video, fps, frame_count, s_width, s_height, num_of_frames = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if num_of_frames is not None:\n",
    "        video_arr_with_req_num_frames = []\n",
    "        '''\n",
    "        If duration of video is greater than required num of frames, then extract a frame for each second until it equal to the required num_of_frames\n",
    "        \n",
    "        if available total num of frames in the video is greater than required num_of_frames, then select a subset of frames\n",
    "    \n",
    "        As per the paper, if the num of frames in video is less than required num of frames, then repeat the video till the frame count equals\n",
    "        required num_of_frames\n",
    "        '''\n",
    "#         duration_of_video = int(math.ceil(frame_count / fps)) # in seconds\n",
    "#         if duration_of_video >= num_of_frames: \n",
    "#             video_arr_with_req_num_frames = get_video_with_frames_every_second(scaled_video, fps, num_of_frames, duration_of_video)\n",
    "            \n",
    "\n",
    "       \n",
    "#         if frame_count > num_of_frames:\n",
    "#             start, end = int(frame_count / 2) - int(num_of_frames / 2), int(frame_count / 2) + int(num_of_frames / 2)\n",
    "#             video_arr_with_req_num_frames = scaled_video[start : end]\n",
    "        \n",
    "        \n",
    "#         elif frame_count < num_of_frames:\n",
    "#             video_arr_with_req_num_frames = np.resize(scaled_video, (num_of_frames, s_height, s_width, 3))\n",
    "#         print(frame_count, num_of_frames)\n",
    "        if frame_count > num_of_frames:\n",
    "            frame_numbers = random.sample(list(np.arange(frame_count - 1).astype(np.uint8)), num_of_frames)\n",
    "            frame_numbers = np.sort(frame_numbers)\n",
    "            \n",
    "            for frame_number in frame_numbers:\n",
    "                video_arr_with_req_num_frames.append(scaled_video[frame_number])\n",
    "            \n",
    "            return video_arr_with_req_num_frames\n",
    "        \n",
    "        elif frame_count == num_of_frames:\n",
    "            return scale_video\n",
    "        \n",
    "        elif frame_count < num_of_frames:\n",
    "            return np.resize(scaled_video, (num_of_frames, s_height, s_width, 3))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def crop_centre_of_each_frame(video_data, crop_size = 224):\n",
    "\n",
    "    cropped_frames = []\n",
    "    num_frames = len(video_data)\n",
    "    for frame_no in range(num_frames):\n",
    "        img = Image.fromarray(video_data[frame_no].astype(np.uint8))\n",
    "        if img.width > img.height:\n",
    "            scale = float(crop_size) / float(img.height)\n",
    "            img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), crop_size))).astype(np.float32)\n",
    "        else:\n",
    "            scale = float(crop_size) / float(img.width)\n",
    "            img = np.array(cv2.resize(np.array(img), (crop_size, int(img.height * scale + 1)))).astype(np.float32)\n",
    "        crop_x = int((img.shape[0] - crop_size) / 2)\n",
    "        crop_y = int((img.shape[1] - crop_size) / 2)\n",
    "        img = img[crop_x:crop_x + crop_size, crop_y:crop_y + crop_size, :]\n",
    "        cropped_frames.append(img)\n",
    "    return cropped_frames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_random_cropping(video_data, crop_size = 224):\n",
    "    video_shape = np.shape(video_data)\n",
    "    max_crop_height = video_shape[1] - crop_size # rows\n",
    "    max_crop_width = video_shape[2] - crop_size # columns\n",
    "    \n",
    "    start_x = random.randint(0, max_crop_width)\n",
    "    start_y = random.randint(0, max_crop_height)\n",
    "    \n",
    "    return video_data[:, start_y : start_y + crop_size, start_x : start_x + crop_size, :]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_optical_flow(video_data):\n",
    "\n",
    "\n",
    "    return_flow_data = []\n",
    "#     video_data = np.dot(video_data, np.array([0.2989, 0.5870, 0.1140]))\n",
    "#     print(np.shape(video_data))\n",
    "    n_prev_frame = video_data[0].astype('uint8')\n",
    "    prev_frame = cv2.cvtColor(n_prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "    num_frames = np.shape(video_data)[0]\n",
    "    hsv = np.zeros_like(video_data[0])\n",
    "    hsv[...,1] = 255\n",
    "    count = 0\n",
    "    for index in range(1, num_frames):\n",
    "        \n",
    "\n",
    "        n_curr_frame  = video_data[index]\n",
    "\n",
    "\n",
    "        n_curr_frame = n_curr_frame.astype('uint8')\n",
    "\n",
    "\n",
    "        curr_frame = cv2.cvtColor(n_curr_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "        flow = optical_flow.calc(prev_frame, curr_frame, None)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "#         rgb = rgb.astype(np.float32)\n",
    "#         rgb[rgb < -20] = -20\n",
    "#         rgb[rgb > 20] = 20\n",
    "#         rgb /= 20\n",
    "        \n",
    "        return_flow_data.append(rgb)\n",
    "        prev_frame = curr_frame\n",
    "    return_flow_data.append(return_flow_data[-1])\n",
    "    return np.asarray(return_flow_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_rgb_video_data(video_data):\n",
    "    video_data = ((video_data / 255.0) * 2) - 1\n",
    "    return video_data\n",
    "\n",
    "\n",
    "\n",
    "def third_dim_to_flow_data(flow_data):\n",
    "    \n",
    "    ret_array = []\n",
    "    for i, frame in enumerate(flow_data):\n",
    "        th = np.zeros((224, 224))\n",
    "        th = th + 0.5\n",
    "        c1, c2 = cv2.split(frame)\n",
    "        c1, c2, th = np.expand_dims(c1, axis = 0), np.expand_dims(c2, axis = 0), np.expand_dims(th, axis = 0)\n",
    "        img = np.concatenate((c1, c2, th), axis = 0)\n",
    "        ret_array.append(img.T)\n",
    "    return np.asarray(ret_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_processing:\n",
    "    def __init__(self):\n",
    "        self.names_labels_dict = {}\n",
    "        self.get_labels_names()\n",
    "\n",
    "    def get_labels_names(self):\n",
    "        self.labels =  os.listdir(config.VIDEOS_PATH)\n",
    "        self.labels = [label for label in self.labels if label != '.DS_Store']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def rename_video_files_names(self, dir_name, path_to_dir):\n",
    "        all_videos_names = os.listdir(path_to_dir)\n",
    "        label_number = self.labels.index(dir_name) # for HMD51, dir name is label\n",
    "        \n",
    "        for count, video_name in enumerate(all_videos_names):\n",
    "            ext_start_index = video_name.rindex('.')\n",
    "            ext = video_name[ext_start_index : ]\n",
    "            source = path_to_dir + video_name\n",
    "            dest = path_to_dir + str(label_number) + '_' + str(count) + ext\n",
    "            \n",
    "            os.rename(source, dest)\n",
    "    \n",
    "    def get_the_rgb_and_flow_data_of_all_videos(self):\n",
    "        all_video_dirs = os.listdir(config.VIDEOS_PATH)\n",
    "        all_video_dirs = [dir_name for dir_name in all_video_dirs if dir_name != '.DS_Store']\n",
    "        num_of_labels = len(self.labels)\n",
    "        for dir_name in all_video_dirs:\n",
    "            if dir_name in ['climb', 'turn']:\n",
    "                label_index = self.labels.index(dir_name)\n",
    "                one_hot_label = np.zeros(num_of_labels)\n",
    "                one_hot_label[label_index] = 1\n",
    "\n",
    "                video_path = config.VIDEOS_PATH + dir_name + '/'\n",
    "                all_videos_names = os.listdir(video_path)\n",
    "                all_videos_names = [name for name in all_videos_names if name != '.DS_Store']\n",
    "    #             print(all_videos_names)\n",
    "                count = 0\n",
    "\n",
    "                for index, video_name in enumerate(all_videos_names):\n",
    "                    if index < 10:\n",
    "                        self.names_labels_dict[video_name] = one_hot_label\n",
    "\n",
    "                        scaled_video, frame_count, fps, s_width, s_height = get_scaled_video(video_path + video_name)\n",
    "                        video_arr_with_req_num_frames = get_req_num_of_frames_from_scaled_video(scaled_video, fps, frame_count, s_width, s_height, 105)\n",
    "                        center_cropped_video = crop_centre_of_each_frame(video_arr_with_req_num_frames)\n",
    "\n",
    "                        ext_index = video_name.rindex('.')\n",
    "                        np.save(config.RGB_ARRAY_DIR + video_name[0 : ext_index] + '.npy', center_cropped_video)\n",
    "\n",
    "                        flow_data = get_optical_flow(center_cropped_video)\n",
    "                        np.save(config.FLOW_ARRAY_DIR + video_name[0 : ext_index] + '.npy', flow_data)\n",
    "                    else:\n",
    "                        break\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#############################################################\n",
    "############## I3D Network####### ###########################\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class I3D:\n",
    "    def __init__(self):\n",
    "        self.VALID_ENDPOINTS = (\n",
    "                                  'Logits',\n",
    "                                  'Predictions',\n",
    "                              )\n",
    "        \n",
    "    \n",
    "    def conv3D_block(self, data, op_channels, \n",
    "                     kernel_shape = [1, 1, 1], \n",
    "                     stride = [1, 1, 1], \n",
    "                     use_activation_fn = True, \n",
    "                     use_batch_norm = True, \n",
    "                     use_bias = False):\n",
    "        \n",
    "        data = Conv3D(filters = op_channels,\n",
    "                      kernel_size = kernel_shape,\n",
    "                      strides = stride,\n",
    "                      padding = 'SAME',\n",
    "                      use_bias = use_bias,\n",
    "                      kernel_regularizer = L1(0.01))(data)\n",
    "        \n",
    "        if use_batch_norm:\n",
    "            data = BatchNormalization()(data)\n",
    "        if use_activation_fn:\n",
    "            data = ReLU()(data)\n",
    "        \n",
    "        return data\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def inception_module(self, data, filters = [64, 96, 128, 16, 32, 32]):\n",
    "        \n",
    "        \n",
    "        \n",
    "        branch_0 = self.conv3D_block(data, op_channels = filters[0], kernel_shape = [1, 1, 1])\n",
    "      \n",
    "        branch_1 = self.conv3D_block(data, op_channels = filters[1], kernel_shape = [1, 1, 1])                 \n",
    "        branch_1 = self.conv3D_block(branch_1, op_channels = filters[2], kernel_shape=[3, 3, 3])\n",
    "      \n",
    "        branch_2 = self.conv3D_block(data, op_channels = filters[3], kernel_shape = [1, 1, 1])\n",
    "        branch_2 = self.conv3D_block(branch_2, op_channels = filters[4], kernel_shape = [3, 3, 3])\n",
    "      \n",
    "        branch_3 = MaxPool3D(pool_size = [3, 3, 3], strides=[1, 1, 1], padding = 'SAME')(data)\n",
    "        branch_3 = self.conv3D_block(branch_3, op_channels = filters[5], kernel_shape = [1, 1, 1])\n",
    "                          \n",
    "        net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
    "    \n",
    "        return net \n",
    "    \n",
    "                                     \n",
    "        \n",
    "    def build(self, end_point, num_of_classes, spatial_squeeze):\n",
    "        if end_point not in self.VALID_ENDPOINTS:\n",
    "            raise ValueError(final_endpoint + ' is not a valid final endpoint')\n",
    "        \n",
    "        input_data = Input(shape = (config.NUM_FRAMES, 224, 224, 3))\n",
    "        \n",
    "        data = self.conv3D_block(input_data, op_channels = 64, kernel_shape=[7, 7, 7], stride = [2, 2, 2])\n",
    "        data = MaxPool3D(pool_size = [1, 3, 3], strides = [1, 2, 2], padding = 'SAME')(data)\n",
    "        data = self.conv3D_block(data, op_channels = 64, kernel_shape = [1, 1, 1])\n",
    "        data = self.conv3D_block(data, op_channels = 192, kernel_shape = [3, 3, 3])\n",
    "        data = MaxPool3D(pool_size = [1, 3, 3], strides = [1, 2, 2], padding = 'SAME')(data)\n",
    "                              \n",
    "        data = self.inception_module(data)       \n",
    "        data = self.inception_module(data, [128, 128, 192, 32, 96, 64])   \n",
    "        data = self.inception_module(data, [128, 128, 192, 32, 96, 64])                              \n",
    "        data = MaxPool3D(pool_size = [3, 3, 3], strides = [2, 2, 2], padding = 'SAME')(data)\n",
    "        data = self.inception_module(data, [192, 96, 208, 16, 48, 64])\n",
    "        data = self.inception_module(data, [160, 112, 224, 24, 64, 64])\n",
    "        data = self.inception_module(data, [128, 128, 256, 24, 64, 64])\n",
    "        data = self.inception_module(data, [112, 144, 288, 32, 64, 64])                          \n",
    "        data = self.inception_module(data, [256, 160, 320, 32, 128, 128])\n",
    "        data = MaxPool3D(pool_size = [2, 2, 2], strides = [2, 2, 2], padding = 'SAME')(data)\n",
    "        data = self.inception_module(data, [256, 160, 320, 32, 128, 128])\n",
    "        data = self.inception_module(data, [384, 192, 284, 48, 128, 128])\n",
    "        data = AveragePooling3D(pool_size = [2, 7, 7], strides = [1, 1, 1], padding = 'VALID')(data)\n",
    "        logits = self.conv3D_block(data, op_channels = num_of_classes, kernel_shape = [1, 1, 1], \n",
    "                                  use_activation_fn = False, use_batch_norm = False, use_bias = True)\n",
    "        \n",
    "        if spatial_squeeze:\n",
    "            logits = tf.squeeze(logits, [2, 3], name = 'SpatialSqueeze')\n",
    "        \n",
    "        if end_point == 'Logits':\n",
    "            averaged_logits = tf.reduce_mean(logits, axis=1)                         \n",
    "#             output = averaged_logits\n",
    "            self.i3d_model = Model(input_data, averaged_logits)\n",
    "        \n",
    "        if end_point == 'Predictions':\n",
    "            averaged_logits = tf.reduce_mean(logits, axis=1)   \n",
    "            predictions = tf.nn.softmax(averaged_logits)\n",
    "#             output = predictions\n",
    "            self.i3d_model = Model(input_data, predictions)\n",
    "                                     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#############################################################\n",
    "######################## Training ###########################\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self):\n",
    "        self.create_dirs()\n",
    "        \n",
    "        i3d_rgb = I3D()\n",
    "        i3d_flow = I3D()\n",
    "        \n",
    "        i3d_rgb.build('Logits', 5, True)\n",
    "        i3d_flow.build('Logits', 5, True)\n",
    "        \n",
    "        self.rgb_model = i3d_rgb.i3d_model\n",
    "        self.flow_model = i3d_flow.i3d_model\n",
    "        \n",
    "        rgb_optimizer = SGD(learning_rate = 0.0001, momentum = 0.9)\n",
    "        flow_optimizer = SGD(learning_rate = 0.0001, momentum = 0.9)\n",
    "#         self.i3d_rgb_checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "#                                                      optimizer = rgb_optimizer,\n",
    "#                                                      model = self.rgb_model)\n",
    "#         self.i3d_rgb_checkpoint_manager = tf.train.CheckpointManager(self.i3d_rgb_checkpoint,\n",
    "#                                                                 directory = config.RGB_CHECKPOINT_DIR,\n",
    "#                                                                 max_to_keep = 3)\n",
    "        \n",
    "#         self.i3d_flow_checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "#                                                       optimizer = flow_optimizer,\n",
    "#                                                       model = self.flow_model)\n",
    "        \n",
    "#         self.i3d_flow_checkpoint_manager = tf.train.CheckpointManager(self.i3d_flow_checkpoint,\n",
    "#                                                               directory = config.FLOW_CHECKPOINT_DIR,\n",
    "#                                                                max_to_keep = 3)\n",
    "        \n",
    "        self.i3d_checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                                  rgb_optimizer = rgb_optimizer,\n",
    "                                                 flow_optimizer = flow_optimizer,\n",
    "                                                 rgb_model = self.rgb_model,\n",
    "                                                 flow_model = self.flow_model\n",
    "                                                 \n",
    "                                                 )\n",
    "        self.i3d_checkpoint_manager = tf.train.CheckpointManager(self.i3d_checkpoint,\n",
    "                                                                directory = config.CHECKPOINT_DIR,\n",
    "                                                                max_to_keep = 3)\n",
    "        \n",
    "    \n",
    "    def create_dirs(self):\n",
    "        if not os.path.exists(config.RGB_CHECKPOINT_DIR):\n",
    "            os.makedirs(config.RGB_CHECKPOINT_DIR)\n",
    "        \n",
    "        if not os.path.exists(config.FLOW_CHECKPOINT_DIR):\n",
    "            os.makedirs(config.FLOW_CHECKPOINT_DIR)\n",
    "            \n",
    "        if not os.path.exists(config.FINAL_WEIGHTS_DIR):\n",
    "            os.makedirs(config.FINAL_WEIGHTS_DIR)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def restore_recent_checkpoint(self):\n",
    "        \n",
    "#         if self.i3d_checkpoint_manager.latest_checkpoint:\n",
    "#             self.i3d_checkpoint.restore(self.i3d_rgb_checkpoint_manager.latest_checkpoint)\n",
    "#             print('loaded rgb checkpoint')\n",
    "        if self.i3d_checkpoint_manager.latest_checkpoint:\n",
    "            self.i3d_checkpoint.rgb_model.load_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_rgb_weights.h5')\n",
    "            self.i3d_checkpoint.flow_model.load_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_flow_weights.h5')\n",
    "            \n",
    "#         if self.i3d_rgb_checkpoint_manager.latest_checkpoint:\n",
    "#             self.i3d_rgb_checkpoint.restore(self.i3d_rgb_checkpoint_manager.latest_checkpoint)\n",
    "#             print('loaded rgb checkpoint')\n",
    "            \n",
    "#         if self.i3d_flow_checkpoint_manager.latest_checkpoint:\n",
    "#             self.i3d_flow_checkpoint.restore(self.i3d_flow_checkpoint_manager.latest_checkpoint)\n",
    "#             print('loaded flow checkpoint')\n",
    "            \n",
    "    \n",
    "    def in_each_train_step(self, rgb_batch, flow_batch, labels):\n",
    "        \n",
    "        with tf.GradientTape(persistent = True) as rgb_tape, tf.GradientTape(persistent = True) as flow_tape:\n",
    "            \n",
    "            print(np.shape(rgb_batch), np.shape(flow_batch), np.shape(labels))\n",
    "            print('-----')\n",
    "            rgb_logits = self.i3d_checkpoint.rgb_model(rgb_batch, training = True)\n",
    "            flow_logits = self.i3d_checkpoint.flow_model(flow_batch, training = True)\n",
    "            print(np.shape(rgb_logits.numpy()), np.shape(flow_logits.numpy()))\n",
    "            \n",
    "            rgb_loss   = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = labels, logits = rgb_logits))\n",
    "            flow_loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = labels, logits = flow_logits))\n",
    "\n",
    "            \n",
    "        print(' one')\n",
    "        rgb_gradients  = rgb_tape.gradient(rgb_loss, self.i3d_checkpoint.rgb_model.trainable_variables)\n",
    "        print('middle')\n",
    "        flow_gradients = flow_tape.gradient(flow_loss, self.i3d_checkpoint.flow_model.trainable_variables)\n",
    "        print('two')\n",
    "        self.i3d_checkpoint.rgb_optimizer.apply_gradients(zip(rgb_gradients, self.i3d_checkpoint.rgb_model.trainable_variables))\n",
    "        self.i3d_checkpoint.flow_optimizer.apply_gradients(zip(flow_gradients, self.i3d_checkpoint.flow_model.trainable_variables))\n",
    "        print('returning')\n",
    "        return rgb_loss, flow_loss\n",
    "    \n",
    "    \n",
    "    def training(self):\n",
    "        self.restore_recent_checkpoint()\n",
    "        num_epochs_finished = self.i3d_checkpoint.curr_epoch.numpy() \n",
    "        \n",
    "        num_epochs_remaining = config.NUM_EPOCHS - num_epochs_finished - 1\n",
    "        \n",
    "        rgb_loss_log = tf.keras.metrics.Mean('rgb_loss', dtype = tf.float32)\n",
    "        flow_loss_log = tf.keras.metrics.Mean('flow_loss', dtype = tf.float32)\n",
    "        \n",
    "        for epoch in range(num_epochs_remaining):\n",
    "            \n",
    "            actual_epoch = self.i3d_checkpoint.curr_epoch.numpy()\n",
    "            \n",
    "            print('epoch ' + str(actual_epoch + epoch))\n",
    "            all_videos_names = os.listdir(config.RGB_ARRAY_DIR)\n",
    "            batch_count = 0\n",
    "            while batch_count < config.NUM_BATCHES_PER_EPOCH:\n",
    "                \n",
    "                batch_video_names = random.sample(all_videos_names, config.BATCH_SIZE)\n",
    "\n",
    "                rgb_data = []\n",
    "                flow_data = []\n",
    "                labels = []\n",
    "                \n",
    "                for video_name in batch_video_names:\n",
    "                    int_label = int(video_name.split('_')[0])\n",
    "                    lb = np.zeros(config.NUM_CLASSES)\n",
    "                    lb[int_label] = 1\n",
    "                    labels.append(lb)\n",
    "                    \n",
    "                    rgb_data.append(np.load(config.RGB_ARRAY_DIR + video_name, allow_pickle = True))\n",
    "                    \n",
    "                    \n",
    "                    f_data = list(np.load(config.FLOW_ARRAY_DIR + video_name, allow_pickle = True))\n",
    "                    f_data.append(f_data[-1])\n",
    "                    flow_data.append(f_data)\n",
    "#                     flow_data.append(np.load(config.FLOW_ARRAY_DIR + video_name, allow_pickle = True))\n",
    "                \n",
    "                \n",
    "                rgb_loss, flow_loss = self.in_each_train_step(np.asarray(rgb_data), \n",
    "                                                              np.asarray(flow_data), \n",
    "                                                              np.asarray(labels))\n",
    "                print(batch_count)\n",
    "                rgb_loss_log.update_state(rgb_loss)\n",
    "                flow_loss_log.update_state(flow_loss)\n",
    "                \n",
    "                batch_count = batch_count + 1\n",
    "                print(batch_count)\n",
    "            if actual_epoch % 9 == 0 and actual_epoch > 0:\n",
    "                print('At epoch ' + str(actual_epoch) + ' rgb loss is ' + str(rgb_loss_log.result()) + ' and flow loss is ' + str(flow_loss_log.result()))\n",
    "                rgb_loss_log.reset_states()\n",
    "                flow_loss_log.reset_states()\n",
    "\n",
    "                self.i3d_checkpoint_manager.save()\n",
    "#                 self.i3d_rgb_checkpoint_manager.save()\n",
    "                self.i3d_checkpoint.rgb_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_rgb_weights.h5')\n",
    "                self.i3d_checkpoint.flow_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_flow_weights.h5')\n",
    "                \n",
    "                print('saved')\n",
    "\n",
    "            if actual_epoch == config.NUM_EPOCHS - 1:\n",
    "                self.i3d_checkpoint.rgb_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_rgb_weights.h5')\n",
    "                self.i3d_checkpoint.flow_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_i3d_flow_weights.h5')\n",
    "                print('training finished')\n",
    "#                     self.gan_checkpoint.d_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_discriminator_weights.h5')\n",
    "\n",
    "            if actual_epoch != config.NUM_EPOCHS - 1:\n",
    "                self.i3d_checkpoint.curr_epoch.assign_add(1)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i3d = Train()\n",
    "train_i3d.training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
